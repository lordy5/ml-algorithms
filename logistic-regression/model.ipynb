{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing, split into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('SVMtrain.csv')\n",
    "\n",
    "# Get rid of unique identifier column\n",
    "data = data.drop('PassengerId', axis=1)\n",
    "\n",
    "# One-hot encoding for 'Sex' column\n",
    "encoded = pd.get_dummies(data, columns=['Sex'])\n",
    "\n",
    "# Split into training and testing data\n",
    "train = encoded.sample(frac=0.8, random_state=200)\n",
    "test = encoded.drop(train.index)\n",
    "\n",
    "# Separate features (x) from target variables (y)\n",
    "train_x, train_y = train.drop('Survived', axis=1), train['Survived']\n",
    "test_x, test_y = train.drop('Survived', axis=1), train['Survived']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([711, 1])\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y = train_x.astype(float), train_y.astype(float)\n",
    "test_x, test_y = test_x.astype(float), test_y.astype(float)\n",
    "\n",
    "train_x_tensor = torch.tensor(train_x.values, dtype=torch.float32)\n",
    "train_y_tensor = torch.tensor(train_y.values, dtype=torch.float32)\n",
    "test_x_tensor = torch.tensor(test_x.values, dtype=torch.float32)\n",
    "test_y_tensor = torch.tensor(test_y.values, dtype=torch.float32)\n",
    "\n",
    "input_size = train_x_tensor.shape[1]\n",
    "\n",
    "train_y_tensor = train_y_tensor.unsqueeze(1)\n",
    "print(train_y_tensor.size())\n",
    "\n",
    "# Define the model\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, 1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 6.1721\n",
      "Epoch 2/10, Loss: 5.0623\n",
      "Epoch 3/10, Loss: 4.2806\n",
      "Epoch 4/10, Loss: 3.6185\n",
      "Epoch 5/10, Loss: 3.0205\n",
      "Epoch 6/10, Loss: 2.5148\n",
      "Epoch 7/10, Loss: 2.0900\n",
      "Epoch 8/10, Loss: 1.7373\n",
      "Epoch 9/10, Loss: 1.4542\n",
      "Epoch 10/10, Loss: 1.2403\n",
      "Epoch 11/10, Loss: 1.0878\n",
      "Epoch 12/10, Loss: 0.9800\n",
      "Epoch 13/10, Loss: 0.9024\n",
      "Epoch 14/10, Loss: 0.8474\n",
      "Epoch 15/10, Loss: 0.8107\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "\n",
    "for epoch in range(15):\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_x_tensor)\n",
    "\n",
    "    loss = loss_function(outputs, train_y_tensor)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{10}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
